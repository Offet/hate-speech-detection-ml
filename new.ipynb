{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "df = pd.read_csv(\"labeled_data.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0  count  hate_speech  offensive_language  neither  class  \\\n",
       "0           0      3            0                   0        3      2   \n",
       "1           1      3            0                   3        0      1   \n",
       "2           2      3            0                   3        0      1   \n",
       "3           3      3            0                   2        1      1   \n",
       "4           4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 24783 entries, 0 to 24782\n",
      "Data columns (total 7 columns):\n",
      " #   Column              Non-Null Count  Dtype \n",
      "---  ------              --------------  ----- \n",
      " 0   Unnamed: 0          24783 non-null  int64 \n",
      " 1   count               24783 non-null  int64 \n",
      " 2   hate_speech         24783 non-null  int64 \n",
      " 3   offensive_language  24783 non-null  int64 \n",
      " 4   neither             24783 non-null  int64 \n",
      " 5   class               24783 non-null  int64 \n",
      " 6   tweet               24783 non-null  object\n",
      "dtypes: int64(6), object(1)\n",
      "memory usage: 1.3+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(         Unnamed: 0         count   hate_speech  offensive_language  \\\n",
       " count  24783.000000  24783.000000  24783.000000        24783.000000   \n",
       " mean   12681.192027      3.243473      0.280515            2.413711   \n",
       " std     7299.553863      0.883060      0.631851            1.399459   \n",
       " min        0.000000      3.000000      0.000000            0.000000   \n",
       " 25%     6372.500000      3.000000      0.000000            2.000000   \n",
       " 50%    12703.000000      3.000000      0.000000            3.000000   \n",
       " 75%    18995.500000      3.000000      0.000000            3.000000   \n",
       " max    25296.000000      9.000000      7.000000            9.000000   \n",
       " \n",
       "             neither         class  \n",
       " count  24783.000000  24783.000000  \n",
       " mean       0.549247      1.110277  \n",
       " std        1.113299      0.462089  \n",
       " min        0.000000      0.000000  \n",
       " 25%        0.000000      1.000000  \n",
       " 50%        0.000000      1.000000  \n",
       " 75%        0.000000      1.000000  \n",
       " max        9.000000      2.000000  ,\n",
       " Unnamed: 0            0\n",
       " count                 0\n",
       " hate_speech           0\n",
       " offensive_language    0\n",
       " neither               0\n",
       " class                 0\n",
       " tweet                 0\n",
       " dtype: int64,\n",
       " (24783, 7),\n",
       " None,\n",
       " 0)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe(), df.isnull().sum(), df.shape, df.info(), df.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Unnamed: 0', 'count', 'hate_speech', 'offensive_language', 'neither',\n",
       "       'class', 'tweet'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...  \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...  \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...  \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...  \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# drop unnecessary columns\n",
    "df.drop(['Unnamed: 0'],\n",
    "        axis=1, inplace=True)\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 1, 0], dtype=int64)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# find the unique values in the class column\n",
    "df[\"class\"].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "import re\n",
    "\n",
    "from nltk.tokenize import word_tokenize\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from wordcloud import WordCloud\n",
    "from collections import Counter\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.corpus import stopwords\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\nuell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>rt woman shouldnt complain cleaning house amp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>rt boy dats coldtyga dwn bad cuffin dat hoe 1s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>rt dawg rt ever fuck bitch start cry confused ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>rt look like tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>rt shit hear might true might faker bitch told...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                                       cleaned_tweet  \n",
       "0  rt woman shouldnt complain cleaning house amp ...  \n",
       "1  rt boy dats coldtyga dwn bad cuffin dat hoe 1s...  \n",
       "2  rt dawg rt ever fuck bitch start cry confused ...  \n",
       "3                                rt look like tranny  \n",
       "4  rt shit hear might true might faker bitch told...  "
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "# define a function to clean the tweet column\n",
    "def clean_text(text):\n",
    "    \"\"\"\n",
    "    Function to clean a tweet by removing URLs, mentions, hashtags, punctuation,\n",
    "    converting text to lowercase, and removing stopwords.\n",
    "    \"\"\"\n",
    "    if isinstance (text, str):# to check if the text is a string\n",
    "        text = re.sub(r\"http\\S+|www\\S+|http\\S+\", \"\", text, flags=re.MULTILINE) #remove urls\n",
    "        text = re.sub(r\"\\@\\w+|\\#\", \"\", text) # remove any hashtags or mentions that could be present \n",
    "        text = re.sub(r\"[^\\w\\s]\", \"\", text) # remove anu punctuations\n",
    "        text = text.lower() # convert characters to lowercases\n",
    "        text = \" \" .join([word for word in text.split() if word not in stop_words]) # to remove stopwords\n",
    "    return text\n",
    "\n",
    "\n",
    "# check if the function works\n",
    "df['cleaned_tweet'] = df['tweet'].apply(clean_text)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\nuell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package punkt is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\nuell\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>count</th>\n",
       "      <th>hate_speech</th>\n",
       "      <th>offensive_language</th>\n",
       "      <th>neither</th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_tweet</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>!!! RT @mayasolovely: As a woman you shouldn't...</td>\n",
       "      <td>rt woman shouldnt complain cleaning house amp ...</td>\n",
       "      <td>rt woman shouldnt complain cleaning house amp ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!! RT @mleew17: boy dats cold...tyga dwn ba...</td>\n",
       "      <td>rt boy dats coldtyga dwn bad cuffin dat hoe 1s...</td>\n",
       "      <td>rt boy dat coldtyga dwn bad cuffin dat hoe 1st...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...</td>\n",
       "      <td>rt dawg rt ever fuck bitch start cry confused ...</td>\n",
       "      <td>rt dawg rt ever fuck bitch start cry confused ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!! RT @C_G_Anderson: @viva_based she lo...</td>\n",
       "      <td>rt look like tranny</td>\n",
       "      <td>rt look like tranny</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>!!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...</td>\n",
       "      <td>rt shit hear might true might faker bitch told...</td>\n",
       "      <td>rt shit hear might true might faker bitch told...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   count  hate_speech  offensive_language  neither  class  \\\n",
       "0      3            0                   0        3      2   \n",
       "1      3            0                   3        0      1   \n",
       "2      3            0                   3        0      1   \n",
       "3      3            0                   2        1      1   \n",
       "4      6            0                   6        0      1   \n",
       "\n",
       "                                               tweet  \\\n",
       "0  !!! RT @mayasolovely: As a woman you shouldn't...   \n",
       "1  !!!!! RT @mleew17: boy dats cold...tyga dwn ba...   \n",
       "2  !!!!!!! RT @UrKindOfBrand Dawg!!!! RT @80sbaby...   \n",
       "3  !!!!!!!!! RT @C_G_Anderson: @viva_based she lo...   \n",
       "4  !!!!!!!!!!!!! RT @ShenikaRoberts: The shit you...   \n",
       "\n",
       "                                       cleaned_tweet  \\\n",
       "0  rt woman shouldnt complain cleaning house amp ...   \n",
       "1  rt boy dats coldtyga dwn bad cuffin dat hoe 1s...   \n",
       "2  rt dawg rt ever fuck bitch start cry confused ...   \n",
       "3                                rt look like tranny   \n",
       "4  rt shit hear might true might faker bitch told...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  rt woman shouldnt complain cleaning house amp ...  \n",
       "1  rt boy dat coldtyga dwn bad cuffin dat hoe 1st...  \n",
       "2  rt dawg rt ever fuck bitch start cry confused ...  \n",
       "3                                rt look like tranny  \n",
       "4  rt shit hear might true might faker bitch told...  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "\n",
    "# Download required NLTK resources\n",
    "nltk.download('punkt')\n",
    "# nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Text Preprocessing Function\n",
    "def preprocess_text(text):\n",
    "    # Tokenization\n",
    "    tokens = word_tokenize(text.lower())\n",
    "    \n",
    "    # Remove stopwords\n",
    "    # stop_words = set(stopwords.words('english'))\n",
    "    # tokens = [token for token in tokens if token not in stop_words]\n",
    "    \n",
    "    # Lemmatization\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    tokens = [lemmatizer.lemmatize(token) for token in tokens]\n",
    "    \n",
    "    return ' '.join(tokens)\n",
    "\n",
    "# Apply preprocessing to text column\n",
    "# df['processed_text'] = df['tweet'].apply(preprocess_text)\n",
    "\n",
    "df['cleaned_text'] = df['cleaned_tweet'].apply(preprocess_text)\n",
    "df.head()\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert text to TF-IDF features\n",
    "vectorizer = TfidfVectorizer(max_df=0.8, max_features=100, stop_words='english')\n",
    "X_vect = vectorizer.fit_transform(df['cleaned_text'])\n",
    "\n",
    "# Apply PCA for dimensionality reduction\n",
    "pca = PCA(n_components=15) \n",
    "X_dense = X_vect.toarray()\n",
    "reduced_features = pca.fit_transform(X_dense)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle outliers using IQR method\n",
    "def remove_outliers(X):\n",
    "    Q1 = np.percentile(X, 25, axis=0)\n",
    "    Q3 = np.percentile(X, 75, axis=0)\n",
    "    IQR = Q3 - Q1\n",
    "    outlier_mask = ~((X < (Q1 - 1.5 * IQR)) | (X > (Q3 + 1.5 * IQR))).any(axis=1)\n",
    "    return X[outlier_mask], outlier_mask\n",
    "\n",
    "# Remove outliers\n",
    "X_clean, outlier_mask = remove_outliers(reduced_features)\n",
    "y_clean = df['class'][outlier_mask]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert x_dense to df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Building the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression Accuracy: 0.7636113025499656\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.00      0.00      0.00       118\n",
      "           1       0.87      0.83      0.85       959\n",
      "           2       0.59      0.83      0.69       374\n",
      "\n",
      "    accuracy                           0.76      1451\n",
      "   macro avg       0.48      0.55      0.51      1451\n",
      "weighted avg       0.72      0.76      0.74      1451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "\n",
    "\n",
    "# Split data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_clean, y_clean, test_size=0.2, random_state=42)\n",
    "\n",
    "# Scale data for Logistic Regression\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n",
    "\n",
    "# Logistic Regression\n",
    "lr_model = LogisticRegression()\n",
    "lr_model.fit(X_train_scaled, y_train)\n",
    "y_pred_lr = lr_model.predict(X_test_scaled)\n",
    "\n",
    "print(\"Logistic Regression Accuracy:\", accuracy_score(y_test, y_pred_lr))\n",
    "print(classification_report(y_test, y_pred_lr))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest Accuracy: 0.7911784975878704\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.40      0.08      0.14       118\n",
      "           1       0.88      0.86      0.87       959\n",
      "           2       0.64      0.85      0.73       374\n",
      "\n",
      "    accuracy                           0.79      1451\n",
      "   macro avg       0.64      0.60      0.58      1451\n",
      "weighted avg       0.78      0.79      0.77      1451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# trying with random forest\n",
    "\n",
    "rf_model = RandomForestClassifier()\n",
    "rf_model.fit(X_train, y_train)\n",
    "y_pred_rf = rf_model.predict(X_test)\n",
    "\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Hyperparameter Tuning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 300}\n",
      "Random Forest Accuracy: 0.7877325982081324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.04      0.08       118\n",
      "           1       0.87      0.85      0.86       959\n",
      "           2       0.63      0.86      0.73       374\n",
      "\n",
      "    accuracy                           0.79      1451\n",
      "   macro avg       0.74      0.58      0.56      1451\n",
      "weighted avg       0.80      0.79      0.76      1451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 200, 300], \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'max_features': ['sqrt', 'log2']  \n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best Random Forest model\n",
    "best_rf_model = rf_grid.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "print(\"Best Random Forest Parameters:\", rf_grid.best_params_)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 400}\n",
      "Random Forest Accuracy: 0.7904893177119228\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.57      0.03      0.06       118\n",
      "           1       0.88      0.86      0.87       959\n",
      "           2       0.63      0.86      0.73       374\n",
      "\n",
      "    accuracy                           0.79      1451\n",
      "   macro avg       0.69      0.58      0.55      1451\n",
      "weighted avg       0.79      0.79      0.77      1451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [100, 200, 300, 400], \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'max_features': ['sqrt', 'log2']  \n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best Random Forest model\n",
    "best_rf_model = rf_grid.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "print(\"Best Random Forest Parameters:\", rf_grid.best_params_)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# # Hyperparameter tuning for Random Forest\n",
    "# rf_param_grid = {\n",
    "#     'n_estimators': [150, 200, 250, 300], \n",
    "#     'max_depth': [None, 10,10,30],\n",
    "#     'min_samples_split': [2, 5, 10],  \n",
    "#     'min_samples_leaf': [1, 2, 4],  \n",
    "#     'max_features': ['sqrt', 'log2']  \n",
    "# }\n",
    "# rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5, scoring='accuracy')\n",
    "# rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# # Best Random Forest model\n",
    "# best_rf_model = rf_grid.best_estimator_\n",
    "# y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "# print(\"Best Random Forest Parameters:\", rf_grid.best_params_)\n",
    "# print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "# print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 310}\n",
      "Random Forest Accuracy: 0.7877325982081324\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.71      0.04      0.08       118\n",
      "           1       0.87      0.85      0.86       959\n",
      "           2       0.63      0.86      0.72       374\n",
      "\n",
      "    accuracy                           0.79      1451\n",
      "   macro avg       0.74      0.58      0.56      1451\n",
      "weighted avg       0.80      0.79      0.76      1451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [110, 210, 310, 410], \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'max_features': ['sqrt', 'log2']  \n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best Random Forest model\n",
    "best_rf_model = rf_grid.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "print(\"Best Random Forest Parameters:\", rf_grid.best_params_)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 150}\n",
      "Random Forest Accuracy: 0.7849758787043418\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.80      0.03      0.07       118\n",
      "           1       0.88      0.85      0.86       959\n",
      "           2       0.62      0.86      0.72       374\n",
      "\n",
      "    accuracy                           0.78      1451\n",
      "   macro avg       0.77      0.58      0.55      1451\n",
      "weighted avg       0.80      0.78      0.76      1451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 100, 150, 200], \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'max_features': ['sqrt', 'log2']  \n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best Random Forest model\n",
    "best_rf_model = rf_grid.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "print(\"Best Random Forest Parameters:\", rf_grid.best_params_)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 2, 'min_samples_split': 10, 'n_estimators': 50}\n",
      "Random Forest Accuracy: 0.7829083390764989\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.03      0.06       118\n",
      "           1       0.87      0.84      0.86       959\n",
      "           2       0.62      0.86      0.72       374\n",
      "\n",
      "    accuracy                           0.78      1451\n",
      "   macro avg       0.72      0.58      0.55      1451\n",
      "weighted avg       0.79      0.78      0.76      1451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [50, 50, 50, 50], \n",
    "    'max_depth': [None, 10, 20, 30],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'max_features': ['sqrt', 'log2']  \n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best Random Forest model\n",
    "best_rf_model = rf_grid.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "print(\"Best Random Forest Parameters:\", rf_grid.best_params_)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 250}\n",
      "Random Forest Accuracy: 0.7842866988283942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.03      0.06       118\n",
      "           1       0.88      0.85      0.86       959\n",
      "           2       0.62      0.86      0.72       374\n",
      "\n",
      "    accuracy                           0.78      1451\n",
      "   macro avg       0.72      0.58      0.55      1451\n",
      "weighted avg       0.79      0.78      0.76      1451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [5000,250, 300, 10], \n",
    "    'max_depth': [None, 10, 30, 20],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'max_features': ['sqrt', 'log2']  \n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best Random Forest model\n",
    "best_rf_model = rf_grid.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "print(\"Best Random Forest Parameters:\", rf_grid.best_params_)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Random Forest Parameters: {'max_depth': 10, 'max_features': 'sqrt', 'min_samples_leaf': 1, 'min_samples_split': 10, 'n_estimators': 250}\n",
      "Random Forest Accuracy: 0.7842866988283942\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.67      0.03      0.06       118\n",
      "           1       0.88      0.85      0.86       959\n",
      "           2       0.62      0.86      0.72       374\n",
      "\n",
      "    accuracy                           0.78      1451\n",
      "   macro avg       0.72      0.58      0.55      1451\n",
      "weighted avg       0.79      0.78      0.76      1451\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "\n",
    "# Hyperparameter tuning for Random Forest\n",
    "rf_param_grid = {\n",
    "    'n_estimators': [600,250, 300, 100], \n",
    "    'max_depth': [None, 10, 30, 50],  \n",
    "    'min_samples_split': [2, 5, 10],  \n",
    "    'min_samples_leaf': [1, 2, 4],  \n",
    "    'max_features': ['sqrt', 'log2']  \n",
    "}\n",
    "rf_grid = GridSearchCV(RandomForestClassifier(random_state=42), rf_param_grid, cv=5, scoring='accuracy')\n",
    "rf_grid.fit(X_train, y_train)\n",
    "\n",
    "# Best Random Forest model\n",
    "best_rf_model = rf_grid.best_estimator_\n",
    "y_pred_rf = best_rf_model.predict(X_test)\n",
    "\n",
    "print(\"Best Random Forest Parameters:\", rf_grid.best_params_)\n",
    "print(\"Random Forest Accuracy:\", accuracy_score(y_test, y_pred_rf))\n",
    "print(classification_report(y_test, y_pred_rf))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Saving The Model For Deployment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement pickle (from versions: none)\n",
      "ERROR: No matching distribution found for pickle\n"
     ]
    }
   ],
   "source": [
    "pip install pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# Save the trained model\n",
    "with open('random_forest_model.pkl', 'wb') as model_file:\n",
    "    pickle.dump(best_rf_model, model_file)\n",
    "\n",
    "# Save the vectorizer\n",
    "with open('tfidf_vectorizer.pkl', 'wb') as vectorizer_file:\n",
    "    pickle.dump(vectorizer, vectorizer_file)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "my_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
